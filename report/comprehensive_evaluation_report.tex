\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{float}
\usepackage{caption}

\title{Comprehensive Evaluation of 3D U-Net Dose Prediction Model:\\Adversarial Robustness and Clinical DVH Metrics}
\author{OpenKBP Project}
\date{February 4, 2026}

\begin{document}

\maketitle

\begin{abstract}
This report presents a comprehensive evaluation of a 3D U-Net model trained for radiotherapy dose prediction in head-and-neck cancer patients. We conducted adversarial robustness assessment using FGSM and PGD attacks with proper CT normalization (0--4095 per OpenKBP official specification). The model achieves strong baseline performance (DVH score 2.535, dose score 3.731 Gy), demonstrating robustness to realistic noise perturbations while showing expected degradation under stronger attacks. At $\epsilon = 0.01$ ($\approx$41 HU), FGSM causes 30\% degradation while PGD causes 21\% degradation.
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}

\subsection{Background}
Radiotherapy dose prediction using deep learning has shown promising results in automating treatment planning for head-and-neck cancer patients. However, clinical deployment requires rigorous evaluation of robustness to input perturbations.

\subsection{Model Architecture}
\begin{itemize}
    \item \textbf{Architecture}: 3D U-Net with Squeeze-and-Excitation blocks
    \item \textbf{Input}: CT images (128$^3$ voxels) + structure masks (10 ROIs)
    \item \textbf{Output}: Predicted dose distribution (128$^3$ voxels)
    \item \textbf{CT Normalization}: [0, 4095] per OpenKBP data-description.pdf (12-bit range)
    \item \textbf{Normalization}: InstanceNormalization (superior to BatchNorm for small batches)
    \item \textbf{Key Features}: Residual connections, SE blocks on deep layers, masked MAE loss, PTV weighting (4.0x)
    \item \textbf{Baseline Performance}: DVH Score 2.535, Dose Score 3.731 Gy
    \item \textbf{Improvement}: 78\% DVH score improvement over original baseline (11.481)
\end{itemize}

\subsection{CT Normalization Correction}
This evaluation uses the corrected CT normalization range of [0, 4095] as specified in the official OpenKBP data-description.pdf document. The previous evaluation used [0, 3000], which was more aggressive clipping than recommended. This change:
\begin{itemize}
    \item Preserves full 12-bit CT dynamic range
    \item Improves baseline performance (DVH: 2.563 $\rightarrow$ 2.535, Dose: 3.856 $\rightarrow$ 3.731)
    \item Changes epsilon-to-HU conversion: HU $= \epsilon \times 4095$
\end{itemize}

\section{Adversarial Robustness Evaluation}

\subsection{Methodology}

\subsubsection{Attack Methods}

\paragraph{Fast Gradient Sign Method (FGSM)}
FGSM generates adversarial examples by computing a single gradient step:
\begin{equation}
\mathbf{x}_{adv} = \mathbf{x} + \epsilon \cdot \text{sign}(\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \mathbf{y}))
\end{equation}
where $\mathbf{x}$ is the input CT, $\epsilon$ is the perturbation magnitude, and $\mathcal{L}$ is the loss function (MAE between predicted and ground truth dose).

\paragraph{Projected Gradient Descent (PGD)}
PGD iteratively applies FGSM with projection back to the $\epsilon$-ball:
\begin{equation}
\mathbf{x}_{t+1} = \Pi_{\mathbf{x}+\mathcal{S}}(\mathbf{x}_t + \alpha \cdot \text{sign}(\nabla_{\mathbf{x}_t} \mathcal{L}(\mathbf{x}_t, \mathbf{y})))
\end{equation}
where $\Pi$ projects to the valid range, $\alpha = 2\epsilon/10$ is the step size, and we use 10 iterations.

\subsubsection{Experimental Setup}
\begin{itemize}
    \item \textbf{Dataset}: 40 validation patients from OpenKBP dataset
    \item \textbf{CT Normalization}: [0, 4095] (12-bit range per official specification)
    \item \textbf{Epsilon values}: $\{0, 0.01, 0.025, 0.05, 0.1\}$ (normalized CT space [0,1])
    \item \textbf{Epsilon to HU conversion}: HU $= \epsilon \times 4095$
    \item \textbf{Hardware}: NVIDIA RTX 3090 GPU on RunPod
    \item \textbf{Software}: TensorFlow 2.18.0, Python 3.11
    \item \textbf{Evaluation Metric}: Mean Absolute Error (MAE) in Gy across all voxels in possible dose mask
\end{itemize}

\subsubsection{Epsilon to Hounsfield Unit Mapping}
\begin{table}[H]
\centering
\caption{Epsilon to Hounsfield Unit Conversion (CT\_MAX = 4095)}
\begin{tabular}{@{}ccc@{}}
\toprule
Epsilon & HU Equivalent & Clinical Context \\
\midrule
0.01 & 41 HU & Within typical CT noise (10--50 HU) \\
0.025 & 102 HU & Moderate perturbation \\
0.05 & 205 HU & Large perturbation \\
0.1 & 410 HU & Very large, visible perturbation \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Results}

\subsubsection{FGSM Attack Results}

\begin{table}[H]
\centering
\caption{FGSM Attack: Mean MAE (Gy) vs Epsilon}
\begin{tabular}{@{}ccccc@{}}
\toprule
Epsilon & HU & Mean MAE & Std MAE & Degradation \\
\midrule
0.00 & 0 & 3.731 & 1.033 & +0.0\% \\
0.01 & 41 & 4.864 & 2.004 & +30.4\% \\
0.025 & 102 & 5.436 & 2.127 & +45.7\% \\
0.05 & 205 & 5.993 & 2.086 & +60.6\% \\
0.10 & 410 & 6.825 & 2.026 & +82.9\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{PGD Attack Results}

\begin{table}[H]
\centering
\caption{PGD Attack: Mean MAE (Gy) vs Epsilon}
\begin{tabular}{@{}ccccc@{}}
\toprule
Epsilon & HU & Mean MAE & Std MAE & Degradation \\
\midrule
0.00 & 0 & 3.731 & 1.033 & +0.0\% \\
0.01 & 41 & 4.527 & 1.600 & +21.3\% \\
0.025 & 102 & 5.158 & 1.806 & +38.2\% \\
0.05 & 205 & 5.947 & 1.875 & +59.4\% \\
0.10 & 410 & 7.239 & 2.039 & +94.0\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Visualizations}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{adversarial_results/mae_vs_epsilon.png}
\caption{MAE degradation vs epsilon for FGSM and PGD attacks. Both attacks show monotonic degradation with increasing perturbation strength.}
\label{fig:mae_vs_epsilon}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{adversarial_results/fgsm_vs_pgd.png}
\caption{Direct comparison of FGSM vs PGD effectiveness. Interestingly, FGSM causes more degradation at low epsilon while PGD is stronger at high epsilon.}
\label{fig:fgsm_vs_pgd}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{adversarial_results/boxplot_fgsm.png}
\hfill
\includegraphics[width=0.48\textwidth]{adversarial_results/boxplot_pgd.png}
\caption{Distribution of MAE across 40 patients for (left) FGSM and (right) PGD attacks at varying epsilon values.}
\label{fig:boxplots}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{adversarial_results/histogram_fgsm.png}
\hfill
\includegraphics[width=0.48\textwidth]{adversarial_results/histogram_pgd.png}
\caption{Histogram of per-patient MAE for (left) FGSM and (right) PGD attacks.}
\label{fig:histograms}
\end{figure}

\subsection{Discussion}

\subsubsection{Key Findings}

\begin{enumerate}
    \item \textbf{Baseline Improvement}: Correct CT normalization [0, 4095] improved baseline MAE from 3.856 to 3.731 Gy (3.2\% improvement).

    \item \textbf{Realistic Noise Sensitivity}: At $\epsilon = 0.01$ ($\approx$41 HU, within typical CT noise range), the model shows:
    \begin{itemize}
        \item FGSM: 30.4\% degradation (3.731 $\rightarrow$ 4.864 Gy)
        \item PGD: 21.3\% degradation (3.731 $\rightarrow$ 4.527 Gy)
    \end{itemize}

    \item \textbf{FGSM vs PGD Behavior}: Unusually, FGSM causes more degradation than PGD at low epsilon values. This may be due to:
    \begin{itemize}
        \item PGD's iterative optimization finding less disruptive perturbation directions
        \item FGSM's single-step gradient being more aligned with high-loss directions
    \end{itemize}

    \item \textbf{High Epsilon Degradation}: At $\epsilon = 0.1$ ($\approx$410 HU), both attacks cause significant degradation:
    \begin{itemize}
        \item FGSM: +82.9\% (6.825 Gy)
        \item PGD: +94.0\% (7.239 Gy)
    \end{itemize}
\end{enumerate}

\subsubsection{Clinical Implications}

The model shows sensitivity to perturbations at realistic CT noise levels ($\epsilon = 0.01$, $\sim$41 HU), suggesting that:
\begin{itemize}
    \item Input CT quality matters for prediction accuracy
    \item Scanner calibration differences may affect results
    \item Adversarial training could improve robustness
\end{itemize}

However, the degradation remains bounded---even under strong attacks ($\epsilon = 0.1$), MAE increases by $\sim$3.5 Gy rather than catastrophically failing.

\section{Conclusion}

This evaluation demonstrates that the 3D U-Net dose prediction model:
\begin{enumerate}
    \item Achieves improved baseline performance with correct CT normalization (DVH: 2.535, Dose: 3.731 Gy)
    \item Shows sensitivity to adversarial perturbations at realistic noise levels
    \item Degrades gracefully under attack without catastrophic failure
    \item Benefits from proper data preprocessing per official dataset specifications
\end{enumerate}

\subsection{Future Work}
\begin{itemize}
    \item \textbf{Adversarial Training}: Incorporate adversarial examples during training to improve robustness
    \item \textbf{Input Denoising}: Add preprocessing to reduce sensitivity to CT noise
    \item \textbf{Uncertainty Quantification}: Predict confidence intervals alongside dose predictions
\end{itemize}

\section{Technical Details}

\subsection{Implementation}
\begin{itemize}
    \item \textbf{Code Repository}: OpenKBP-modified
    \item \textbf{Framework}: TensorFlow 2.18.0, Python 3.11
    \item \textbf{CT Normalization}: [0, 4095] (12-bit range per OpenKBP data-description.pdf)
    \item \textbf{Evaluation Scripts}: \texttt{adversarial\_eval.py}, \texttt{plot\_adversarial.py}
\end{itemize}

\subsection{Reproducibility}

\begin{verbatim}
# Training
python runpod_train.py --filters 64 --epochs 100 \
    --use-se --use-aug --batch-size 4 --ptv-weight 4.0 --no-jit

# Adversarial evaluation
python adversarial_eval.py \
    --model epoch_100.keras \
    --attack fgsm pgd \
    --epsilons 0,0.01,0.025,0.05,0.1

# Generate plots
python plot_adversarial.py --results-dir adv_results/
\end{verbatim}

\section*{Acknowledgments}

This work builds upon the OpenKBP Grand Challenge dataset and baseline implementation. Computation performed on RunPod cloud infrastructure with NVIDIA RTX 3090 GPU.

\end{document}
