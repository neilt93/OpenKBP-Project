\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{float}
\usepackage{caption}

\title{Adversarial Robustness Evaluation of 3D U-Net Dose Prediction:\\Dose Score Sensitivity to CT Perturbations}
\author{OpenKBP Project}
\date{February 4, 2026}

\begin{document}

\maketitle

\begin{abstract}
This report evaluates the adversarial robustness of a 3D U-Net model trained for radiotherapy dose prediction in head-and-neck cancer patients. We assess sensitivity to CT input perturbations using FGSM and PGD attacks, measuring degradation in dose score (voxel-wise MAE). The model achieves baseline performance of DVH score 2.535 and dose score 3.731 Gy. Under adversarial perturbation at $\epsilon = 0.01$ ($\approx$41 HU), dose score degrades by 30\% (FGSM) and 21\% (PGD). This study focuses on dose score sensitivity; DVH score under attack is noted as future work.
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}

\subsection{Background}
Radiotherapy dose prediction using deep learning has shown promising results in automating treatment planning for head-and-neck cancer patients. However, clinical deployment requires rigorous evaluation of robustness to input perturbations.

\subsection{Metric Definitions}

\begin{table}[H]
\centering
\caption{OpenKBP Evaluation Metrics}
\begin{tabular}{@{}lp{10cm}@{}}
\toprule
Metric & Definition \\
\midrule
\textbf{Dose Score} & Mean Absolute Error (MAE) in Gy, computed over all voxels within the \texttt{possible\_dose\_mask} region. Lower is better. \\
\textbf{DVH Score} & Mean absolute error of DVH statistics ($D_1$, $D_{95}$, $D_{99}$, mean dose) across all anatomical structures. Lower is better. \\
\bottomrule
\end{tabular}
\end{table}

\noindent\textbf{Note}: This adversarial evaluation reports \textbf{dose score} degradation under attack. DVH score evaluation under adversarial perturbation is left for future work.

\subsection{Model Architecture}
\begin{itemize}
    \item \textbf{Architecture}: 3D U-Net with Squeeze-and-Excitation blocks
    \item \textbf{Input}: CT images (128$^3$ voxels) + structure masks (10 ROIs)
    \item \textbf{Output}: Predicted dose distribution (128$^3$ voxels)
    \item \textbf{CT Normalization}: [0, 4095] per OpenKBP data-description.pdf (12-bit range)
    \item \textbf{Normalization}: InstanceNormalization (superior to BatchNorm for small batches)
    \item \textbf{Key Features}: Residual connections, SE blocks on deep layers, masked MAE loss, PTV weighting (4.0$\times$)
    \item \textbf{Baseline Performance}: DVH Score 2.535, Dose Score 3.731 Gy
    \item \textbf{Improvement}: 78\% DVH score improvement over original baseline (11.481)
\end{itemize}

\subsection{CT Normalization Correction}
This evaluation uses the corrected CT normalization range of [0, 4095] as specified in the official OpenKBP data-description.pdf document. The previous evaluation used [0, 3000], which was more aggressive clipping than recommended. This change:
\begin{itemize}
    \item Preserves full 12-bit CT dynamic range
    \item Improves baseline performance (DVH: 2.563 $\rightarrow$ 2.535, Dose: 3.856 $\rightarrow$ 3.731)
    \item Changes epsilon-to-HU conversion factor
\end{itemize}

\section{Adversarial Robustness Evaluation}

\subsection{Methodology}

\subsubsection{Threat Model}

This evaluation uses a \textbf{white-box} adversarial setting:
\begin{itemize}
    \item \textbf{Perturbation target}: CT input only; structure masks remain unchanged
    \item \textbf{Attack objective}: Maximize dose prediction error using ground-truth dose in the loss function
    \item \textbf{Interpretation}: This measures worst-case model sensitivity to CT perturbations, not a realistic deployment attack scenario (where ground-truth dose would be unavailable to an attacker)
\end{itemize}

\subsubsection{Attack Methods}

\paragraph{Fast Gradient Sign Method (FGSM)}
FGSM generates adversarial examples by computing a single gradient step:
\begin{equation}
\mathbf{x}_{adv} = \mathbf{x} + \epsilon \cdot \text{sign}(\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \mathbf{y}))
\end{equation}
where $\mathbf{x}$ is the input CT, $\epsilon$ is the perturbation magnitude, and $\mathcal{L}$ is the loss function (MAE between predicted and ground truth dose).

\paragraph{Projected Gradient Descent (PGD)}
PGD iteratively applies FGSM with projection back to the $\epsilon$-ball:
\begin{equation}
\mathbf{x}_{t+1} = \Pi_{\mathbf{x}+\mathcal{S}}(\mathbf{x}_t + \alpha \cdot \text{sign}(\nabla_{\mathbf{x}_t} \mathcal{L}(\mathbf{x}_t, \mathbf{y})))
\end{equation}
where $\Pi$ projects to the valid range [0, 1], $\alpha = 2\epsilon/10$ is the step size, and we use 10 iterations. Our implementation does not use random initialization within the $\epsilon$-ball.

\subsubsection{Experimental Setup}
\begin{itemize}
    \item \textbf{Dataset}: 40 validation patients from OpenKBP dataset
    \item \textbf{CT Normalization}: [0, 4095] (12-bit range per official specification)
    \item \textbf{Epsilon values}: $\{0, 0.01, 0.025, 0.05, 0.1\}$ (normalized CT space [0,1])
    \item \textbf{PGD parameters}: 10 iterations, step size $\alpha = 2\epsilon/10$, no random start
    \item \textbf{Hardware}: NVIDIA RTX 3090 GPU on RunPod
    \item \textbf{Software}: TensorFlow 2.18.0, Python 3.11
    \item \textbf{Evaluation Metric}: Dose score (MAE in Gy within possible dose mask)
\end{itemize}

\subsubsection{Epsilon to Hounsfield Unit Mapping}

The HU equivalent assumes the OpenKBP CT encoding uses approximately 1 intensity unit per HU step (after any offset correction) and that normalization divides by 4095. The exact OpenKBP encoding may involve a HU offset (commonly HU + 1024 in DICOM); our conversion provides an approximate clinical reference.

\begin{table}[H]
\centering
\caption{Epsilon to Hounsfield Unit Conversion (CT\_MAX = 4095)}
\begin{tabular}{@{}ccp{6.5cm}@{}}
\toprule
Epsilon & HU Equivalent & Clinical Context \\
\midrule
0.01 & $\sim$41 HU & Often within typical CT noise range (commonly 10--50 HU, varies by scanner/protocol) \\
0.025 & $\sim$102 HU & Moderate perturbation \\
0.05 & $\sim$205 HU & Large perturbation \\
0.1 & $\sim$410 HU & Very large, visible perturbation \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Results}

\subsubsection{FGSM Attack Results}

\begin{table}[H]
\centering
\caption{FGSM Attack: Dose Score (Gy) vs Epsilon}
\begin{tabular}{@{}ccccc@{}}
\toprule
Epsilon & HU & Dose Score & Std & Degradation \\
\midrule
0.00 & 0 & 3.731 & 1.033 & --- \\
0.01 & 41 & 4.864 & 2.004 & +30.4\% \\
0.025 & 102 & 5.436 & 2.127 & +45.7\% \\
0.05 & 205 & 5.993 & 2.086 & +60.6\% \\
0.10 & 410 & 6.825 & 2.026 & +82.9\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{PGD Attack Results}

\begin{table}[H]
\centering
\caption{PGD Attack: Dose Score (Gy) vs Epsilon}
\begin{tabular}{@{}ccccc@{}}
\toprule
Epsilon & HU & Dose Score & Std & Degradation \\
\midrule
0.00 & 0 & 3.731 & 1.033 & --- \\
0.01 & 41 & 4.527 & 1.600 & +21.3\% \\
0.025 & 102 & 5.158 & 1.806 & +38.2\% \\
0.05 & 205 & 5.947 & 1.875 & +59.4\% \\
0.10 & 410 & 7.239 & 2.039 & +94.0\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Visualizations}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{adversarial_results/mae_vs_epsilon.png}
\caption{Dose score degradation vs epsilon for FGSM and PGD attacks. Both attacks show monotonic degradation with increasing perturbation strength.}
\label{fig:mae_vs_epsilon}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{adversarial_results/fgsm_vs_pgd.png}
\caption{Comparison of FGSM vs PGD effectiveness. FGSM causes more degradation at low epsilon ($\leq 0.025$), while PGD is stronger at high epsilon ($\geq 0.05$). See Section~\ref{sec:sanity} for discussion.}
\label{fig:fgsm_vs_pgd}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{adversarial_results/boxplot_fgsm.png}
\hfill
\includegraphics[width=0.48\textwidth]{adversarial_results/boxplot_pgd.png}
\caption{Distribution of dose score across 40 patients for (left) FGSM and (right) PGD attacks at varying epsilon values.}
\label{fig:boxplots}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{adversarial_results/histogram_fgsm.png}
\hfill
\includegraphics[width=0.48\textwidth]{adversarial_results/histogram_pgd.png}
\caption{Histogram of per-patient dose score for (left) FGSM and (right) PGD attacks.}
\label{fig:histograms}
\end{figure}

\subsection{Discussion}

\subsubsection{Key Findings}

\begin{enumerate}
    \item \textbf{Baseline Improvement}: Correct CT normalization [0, 4095] improved baseline dose score from 3.856 to 3.731 Gy (3.2\% improvement).

    \item \textbf{Noise-Level Sensitivity}: At $\epsilon = 0.01$ ($\sim$41 HU, often within the range of typical CT scanner noise), the model shows:
    \begin{itemize}
        \item FGSM: 30.4\% degradation (3.731 $\rightarrow$ 4.864 Gy)
        \item PGD: 21.3\% degradation (3.731 $\rightarrow$ 4.527 Gy)
    \end{itemize}

    \item \textbf{FGSM vs PGD at Low Epsilon}: At $\epsilon \leq 0.025$, FGSM causes more degradation than PGD. This is atypical for standard adversarial evaluations. See Section~\ref{sec:sanity} for analysis.

    \item \textbf{High Epsilon Degradation}: At $\epsilon = 0.1$ ($\sim$410 HU), both attacks cause significant degradation:
    \begin{itemize}
        \item FGSM: +82.9\% (6.825 Gy)
        \item PGD: +94.0\% (7.239 Gy)
    \end{itemize}
\end{enumerate}

\subsubsection{PGD Sanity Checks and FGSM vs PGD Analysis}
\label{sec:sanity}

The observation that FGSM outperforms PGD at low epsilon is atypical. We verified the following:

\begin{itemize}
    \item \textbf{Gradient validity}: Gradients are confirmed non-zero and finite (no NaN/Inf values)
    \item \textbf{Step size}: Current $\alpha = 2\epsilon/10 = 0.2\epsilon$ may be suboptimal; smaller step sizes ($\alpha = \epsilon/10$) or more iterations (20--40) could improve PGD effectiveness
    \item \textbf{Random initialization}: Our PGD implementation does not use random start within the $\epsilon$-ball, which can reduce PGD strength in some settings
    \item \textbf{Projection}: Clipping to [0, 1] is correctly applied after each step
\end{itemize}

\textbf{Recommended follow-up experiments}:
\begin{enumerate}
    \item PGD with random initialization in $[-\epsilon, +\epsilon]$
    \item Step sizes $\alpha \in \{\epsilon/10, \epsilon/4\}$ with 20--40 iterations
    \item Best-of-$N$ restarts ($N = 5$)
\end{enumerate}

If FGSM still outperforms PGD at low epsilon after these checks, this would suggest either (a) gradient masking effects, or (b) the single-step FGSM direction is more aligned with high-loss regions than iterative refinement achieves for this architecture.

\subsubsection{Clinical Implications}

The model shows sensitivity to perturbations at magnitudes that are often on the order of typical CT scanner noise ($\epsilon = 0.01$, $\sim$41 HU), suggesting that:
\begin{itemize}
    \item Input CT quality may affect prediction accuracy
    \item Scanner calibration differences could impact results
    \item Adversarial training may improve robustness
\end{itemize}

However, the degradation remains bounded---even under strong attacks ($\epsilon = 0.1$), dose score increases by $\sim$3.5 Gy rather than failing catastrophically.

\subsubsection{Limitations}

\begin{itemize}
    \item \textbf{DVH score not evaluated}: This study reports dose score (voxel-wise MAE) under attack. DVH score may degrade differently, particularly for structure-specific metrics.
    \item \textbf{White-box assumption}: Real attackers would not have access to ground-truth dose; this evaluation measures sensitivity, not exploitability.
    \item \textbf{HU conversion approximate}: The epsilon-to-HU mapping assumes 1:1 correspondence between stored intensity and HU steps, which may not hold exactly for all CT encodings.
\end{itemize}

\section{Conclusion}

This evaluation demonstrates that the 3D U-Net dose prediction model:
\begin{enumerate}
    \item Achieves strong baseline performance with correct CT normalization (DVH: 2.535, Dose: 3.731 Gy)
    \item Shows dose score sensitivity to adversarial perturbations at noise-level magnitudes
    \item Degrades gracefully under attack without catastrophic failure
    \item Benefits from proper data preprocessing per official dataset specifications
\end{enumerate}

\subsection{Future Work}
\begin{itemize}
    \item \textbf{DVH Score Under Attack}: Evaluate DVH metrics degradation under adversarial perturbation
    \item \textbf{PGD Improvements}: Implement random starts and tune step size/iterations
    \item \textbf{Adversarial Training}: Incorporate adversarial examples during training to improve robustness
    \item \textbf{Input Denoising}: Add preprocessing to reduce sensitivity to CT noise
    \item \textbf{Uncertainty Quantification}: Predict confidence intervals alongside dose predictions
\end{itemize}

\section{Technical Details}

\subsection{Implementation}
\begin{itemize}
    \item \textbf{Code Repository}: OpenKBP-modified
    \item \textbf{Framework}: TensorFlow 2.18.0, Python 3.11
    \item \textbf{CT Normalization}: [0, 4095] (12-bit range per OpenKBP data-description.pdf)
    \item \textbf{Evaluation Scripts}: \texttt{adversarial\_eval.py}, \texttt{plot\_adversarial.py}
\end{itemize}

\subsection{Reproducibility}

\begin{verbatim}
# Training
python runpod_train.py --filters 64 --epochs 100 \
    --use-se --use-aug --batch-size 4 --ptv-weight 4.0 --no-jit

# Adversarial evaluation
python adversarial_eval.py \
    --model epoch_100.keras \
    --attack fgsm pgd \
    --epsilons 0,0.01,0.025,0.05,0.1

# Generate plots
python plot_adversarial.py --results-dir adv_results/
\end{verbatim}

\section*{Acknowledgments}

This work builds upon the OpenKBP Grand Challenge dataset and baseline implementation. Computation performed on RunPod cloud infrastructure with NVIDIA RTX 3090 GPU.

\end{document}
